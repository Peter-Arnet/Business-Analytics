{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6: More pandas and intro to machine learning\n",
    "\n",
    "_BS1819 Data Structures and Algorithms, September 2018_\n",
    "\n",
    "_Imperial College Business School_\n",
    "\n",
    "\n",
    "---\n",
    "In the previous tutorial, we started working on the _pandas_ data analysis library. In this tutorial, we will briefly go through some of its more advanced features. The optional part of the tutorial provides a teaser to machine learning with a brief introduction to the popular _scikit learn_ library.\n",
    "\n",
    "---\n",
    "\n",
    "## Submission\n",
    "\n",
    "There are no OK tests or required submission for this tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Titanic\n",
    "\n",
    "The tutorial folder contains the files `titanic.csv` and `nationalities.csv`. The latter file contains nationalities of Titanic passengers. Note that this file was created solely for the purpose of learning within this course, and should not be used outside of the scope of the course. It does **not** reflect the real nationalities of the passengers.\n",
    "\n",
    "Load the files titanic.csv and nationalities.csv in the variables `data_org` and `data_nat` respectively. Use the cell below as instructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reads the file titanic.csv\n",
    "data_org = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Reads the file nationalities.csv\n",
    "data_nat = pd.read_csv('nationalities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced pandas dataframe processing\n",
    "\n",
    "When working on data analysis, we often need to combine information from different sources, or produce our own data and then combine them with other sources. The pandas library offers a great deal of methods to facilitate this process. We will study below the functionality of merging datasets. We will merge the titanic.csv (original file) and the nationalities.csv (data produced by our research). \n",
    "\n",
    "Before merging two datasets, we need to know exactly how these datasets are related, how they are structured and whether they already have some common fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # First, let's ensure that the two datasets have the same number of elements (passenger data).\n",
    "assert data_org.shape[0] == data_nat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Let's print the heads of the two datasets to figure out if there are any common elements.\n",
    "data_org.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Swede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Austro Hungarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Swede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Belgian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Swede</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId       Nationality\n",
       "0            1             Swede\n",
       "1            2  Austro Hungarian\n",
       "2            3             Swede\n",
       "3            4           Belgian\n",
       "4            5             Swede"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Swede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Austro Hungarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Swede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Belgian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Swede</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked       Nationality  \n",
       "0      0         A/5 21171   7.2500   NaN        S             Swede  \n",
       "1      0          PC 17599  71.2833   C85        C  Austro Hungarian  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S             Swede  \n",
       "3      0            113803  53.1000  C123        S           Belgian  \n",
       "4      0            373450   8.0500   NaN        S             Swede  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # We are ready to perform the merging. Observe that the datasets share a common column in\n",
    "# # the PassengerId, so we will use it to combine the data.\n",
    "data_new = data_org.merge(data_nat, on='PassengerId')\n",
    "\n",
    "# # Let's see what we've created now.\n",
    "data_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "1    38.233441\n",
      "2    29.877630\n",
      "3    25.140620\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# # Pandas offers several convenient methods for conditional selection and actions on them.\n",
    "# # For instance, in the previous tutorial, we worked on getting useful aggregate statistics\n",
    "# # over the whole dataset (do you remember the commands?).\n",
    "# # However, often we'd like to select only a subset of the data based on some condition. \n",
    "# # For instance, let's say we would like to print the average age per class.\n",
    "# # One way to do that would be to iterate over all the elements, create a list, sum them \n",
    "# # and then compute the average. \n",
    "# # But pandas conveniently allows us to do it with a single command. \n",
    "# # It works as follows: \n",
    "# # First we group the data by the class, then we ask pandas to compute the mean of the age.\n",
    "print(data_new.groupby(['Pclass'])['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass  Sex   \n",
      "1       female    34.611765\n",
      "        male      41.281386\n",
      "2       female    28.722973\n",
      "        male      30.740707\n",
      "3       female    21.750000\n",
      "        male      26.507589\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# # In the command above, we've averaged both men and women based only on the Pclass.\n",
    "# # However, we could separate the two sexes and compute the mean for each sex.\n",
    "print(data_new.groupby(['Pclass', 'Sex'])['Age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noted that in class three, the average age of each sex differs significantly with the mean being closer to the male average age. Intuitively, you expect to find more men in that class than women. However, what is the command to find the exact number of males in this class? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # We will now drop few columns that contain strings to mention few methods for statistical processing.\n",
    "data = data_new.drop(['Cabin', 'Name', 'Ticket', 'Embarked', 'Nationality', 'Sex'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age  SibSp  Parch    Fare\n",
       "0          1.0       0.0     3.0  22.0    1.0    0.0   7.250\n",
       "1          2.0       1.0     1.0  38.0    1.0    0.0  40.000\n",
       "2          3.0       1.0     3.0  26.0    0.0    0.0   7.925\n",
       "3          4.0       1.0     1.0  35.0    1.0    0.0  40.000\n",
       "4          5.0       0.0     3.0  35.0    0.0    0.0   8.050"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # As we've seen, pandas bundles much of the functionality of numpy and lists.\n",
    "# # We can for example \"clip\" the values, i.e. restrict them in a chosen interval.\n",
    "# # Notice that some values were greater than our upper bound, but are now\n",
    "# # restricted to the maximum upper bound we set.\n",
    "data.clip(lower=0, upper=40).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>SurvivedPlusOne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  SurvivedPlusOne\n",
       "0            1         0       3  22.0      1      0   7.2500                1\n",
       "1            2         1       1  38.0      1      0  71.2833                2\n",
       "2            3         1       3  26.0      0      0   7.9250                2\n",
       "3            4         1       1  35.0      1      0  53.1000                2\n",
       "4            5         0       3  35.0      0      0   8.0500                1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # If the method we would like to apply to the data does not exist, we can use the \n",
    "# # '.apply' method that allows us to choose any function to be applied to each record.\n",
    "# # One way to do this is through an \"anonymous\" lambda function.\n",
    "# # This works as defining a function without an explicit name to apply to each record\n",
    "import numpy as np\n",
    "data[\"SurvivedPlusOne\"] = data[\"Survived\"].apply(lambda x: x + 1)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**. Who survived? Use the aggregation functions above to calculate survival probabilities based on fare classes, age, or fare paid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has been a very brief introduction to data aggregation in pandas. For many more useful methods, see\n",
    "\n",
    "- VanderPlas, Jake. Python Data Science Handbook: https://github.com/jakevdp/PythonDataScienceHandbook\n",
    "- Reda, Greg. Intro to pandas data structures: http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/\n",
    "- Evans, Julia. Pandas cookbook: https://github.com/jvns/pandas-cookbook\n",
    "- Augsburger, Tom. Modern pandas. http://tomaugspurger.github.io/modern-1.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra topic: Introduction to Machine Learning\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "We can think of Machine Learning (ML) as a way to simulate a function. Not necessarily a function with the strict mathematical sense of calculus courses, but rather a function that maps some (optional) input to some output. \n",
    "\n",
    "For instance, translating English to German can be thought as a function that maps text in the English language to the respective text into German. Let's think about that for a minute: The naive approach is to translate word by word, e.g. having a python dictionary with keywords the english words and the respective value to be a german word. However, this approach would lose most of the language's syntax, the connections and the higher level representations of the text. Machine-learning based translation tools seek to bridge this cap and are a very active field in Machine Learning research. \n",
    "\n",
    "Machine Learning approaches typically use some **tunable parameters** (typically an array of floating point values) that are adjusted (learnt) so as to improve their behaviour by **adapting to previously seen data.**\n",
    "\n",
    "Depending on the ML application, you can have different dimensions of data. For example, in image processing, they typically deal with 2D arrays of shape  ``[n_samples x n_features]``. The number of features is the same for each object, and each feature column refers to a related piece of information about each sample. In financial analysis, you also deal with 2D arrays where n_features would be the number of observations in a time series, e.g. the stock price of a company for the past several years. The different samples would then refer to different companies. \n",
    "\n",
    "Machine-learning methods are often divided into *supervised learning* and *unsupervised learning*.\n",
    "\n",
    "Supervised learning relies on having some labelled sample data as input, and training a model to analyse new instances of related data. For example, we might have pictures of different individuals and label each picture with the person who's in the photo, and then train an algorithm to classify new pictures. \n",
    "\n",
    "Unsupervised learning, in contrast, does not require any labelled samples to learn. With the photos, we might instead use unsupervised learning to try to divide our pictures into groups of different people without any upfront labelling. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Learning: Classification and regression\n",
    "\n",
    "In **Supervised Learning**, we have a dataset consisting of different **features and labels**.\n",
    "The task is to construct an estimator which is able to predict the label of an object\n",
    "given the set of features. Some examples are:\n",
    "\n",
    "- given a multicolor image of an object through a telescope, determine\n",
    "  whether that object is a star, a quasar, or a galaxy.\n",
    "- given a photograph of a person, identify the person in the photo.\n",
    "- given a list of movies a person has watched and their personal rating\n",
    "  of the movie, recommend a list of movies they would like\n",
    "  (So-called *recommender systems*: a famous example is the [Netflix Prize](http://en.wikipedia.org/wiki/Netflix_prize)).\n",
    "- given observations from a site (e.g. sensors' input), figure out\n",
    "  whether the facility works as predicted or there are \n",
    "  some disruptions (this task is alleged \"anomaly detection\").\n",
    "\n",
    "What these tasks have in common is that there is one or more unknown\n",
    "quantities associated with the object which needs to be determined from other\n",
    "observed quantities.\n",
    "\n",
    "Supervised learning is further broken down into two categories, **classification** and **regression**.\n",
    "In classification, the label is discrete, while in regression, the label is continuous. For example,\n",
    "in astronomy, the task of determining whether an object is a star, a galaxy, or a quasar is a\n",
    "classification problem: the label is from three distinct categories. On the other hand, we might\n",
    "wish to estimate the age of an object based on such observations: this would be a regression problem,\n",
    "because the label (age) is a continuous quantity.\n",
    "\n",
    "---\n",
    "\n",
    "Both regression and classification are some tasks essential in several fields that require data analysis (e.g. financial analysis). Some examples are:\n",
    "- given historical observations of the house market prices, predict the future values.\n",
    "- given the offers (for outsourcing product $y$ creation) from $v$ different companies, decide with which company to collaborate. \n",
    "- given a history of stock market prices, predict whether there is a disruptive event at some time $t$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no tests for these exercises.\n",
    "\n",
    "** Exercise. ** What type of problem (classification/regression) is the one with house market prices?\n",
    "\n",
    "** Exercise. ** What about the offers for outsourcing the product creation?\n",
    "\n",
    "** Exercise. ** What type of problem is the prediction of disruptive events in stock market?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Scikit learn\n",
    "We'll use a popular machine-learning library called **Scikit learn**. \n",
    "You can start using scikit straight away, as the API is intuitive and well documented. They also offer a plethora of more advanced options if you want to customise the parameters of the optimisation problem.\n",
    "\n",
    "In this tutorial, we focus on regression.  We'll begin with the most standard regression setting: the linear regression one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # We import only the LinearRegression class.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "# # Import the modules for printing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LinearRegression in module sklearn.linear_model.base:\n",
      "\n",
      "class LinearRegression(LinearModel, sklearn.base.RegressorMixin)\n",
      " |  Ordinary least squares Linear Regression.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  fit_intercept : boolean, optional\n",
      " |      whether to calculate the intercept for this model. If set\n",
      " |      to false, no intercept will be used in calculations\n",
      " |      (e.g. data is expected to be already centered).\n",
      " |  \n",
      " |  normalize : boolean, optional, default False\n",
      " |      If True, the regressors X will be normalized before regression.\n",
      " |      This parameter is ignored when `fit_intercept` is set to False.\n",
      " |      When the regressors are normalized, note that this makes the\n",
      " |      hyperparameters learnt more robust and almost independent of the number\n",
      " |      of samples. The same property is not valid for standardized data.\n",
      " |      However, if you wish to standardize, please use\n",
      " |      `preprocessing.StandardScaler` before calling `fit` on an estimator\n",
      " |      with `normalize=False`.\n",
      " |  \n",
      " |  copy_X : boolean, optional, default True\n",
      " |      If True, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  n_jobs : int, optional, default 1\n",
      " |      The number of jobs to use for the computation.\n",
      " |      If -1 all CPUs are used. This will only provide speedup for\n",
      " |      n_targets > 1 and sufficient large problems.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array, shape (n_features, ) or (n_targets, n_features)\n",
      " |      Estimated coefficients for the linear regression problem.\n",
      " |      If multiple targets are passed during the fit (y 2D), this\n",
      " |      is a 2D array of shape (n_targets, n_features), while if only\n",
      " |      one target is passed, this is a 1D array of length n_features.\n",
      " |  \n",
      " |  residues_ : array, shape (n_targets,) or (1,) or empty\n",
      " |      Sum of residuals. Squared Euclidean 2-norm for each target passed\n",
      " |      during the fit. If the linear regression problem is under-determined\n",
      " |      (the number of linearly independent rows of the training matrix is less\n",
      " |      than its number of linearly independent columns), this is an empty\n",
      " |      array. If the target vector passed during the fit is 1-dimensional,\n",
      " |      this is a (1,) shape array.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |  \n",
      " |  intercept_ : array\n",
      " |      Independent term in the linear model.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  From the implementation point of view, this is just plain Ordinary\n",
      " |  Least Squares (scipy.linalg.lstsq) wrapped as a predictor object.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearRegression\n",
      " |      LinearModel\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array or sparse matrix of shape [n_samples,n_features]\n",
      " |          Training data\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples, n_targets]\n",
      " |          Target values\n",
      " |      \n",
      " |      sample_weight : numpy array of shape [n_samples]\n",
      " |          Individual weights for each sample\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             parameter *sample_weight* support to LinearRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  residues_\n",
      " |      DEPRECATED: ``residues_`` is deprecated and will be removed in 0.19\n",
      " |      \n",
      " |      Get the residues of the fitted model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset([])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from LinearModel:\n",
      " |  \n",
      " |  decision_function(*args, **kwargs)\n",
      " |      DEPRECATED:  and will be removed in 0.19.\n",
      " |      \n",
      " |      Decision function of the linear model.\n",
      " |      \n",
      " |              Parameters\n",
      " |              ----------\n",
      " |              X : {array-like, sparse matrix}, shape = (n_samples, n_features)\n",
      " |                  Samples.\n",
      " |      \n",
      " |              Returns\n",
      " |              -------\n",
      " |              C : array, shape = (n_samples,)\n",
      " |                  Returns predicted values.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape = (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the regression\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      Best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # If you want to check out the documentation, \n",
    "# # you can call help().\n",
    "help(LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Let's initialise a new Linear Regression model.\n",
    "model = LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)\n"
     ]
    }
   ],
   "source": [
    "# # In most python libraries, you can print the objects and\n",
    "# # acquire information about their class/parameters.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elaborate on 'Parameters', please...\n",
    "At this point, we should clarify the use of the term **parameters**. \n",
    "\n",
    "In the `help` command a few cells above, you might have noticed that under the title 'Parameters' are the arguments of the class. Those are the programming parameters, provided by the programmer. Those are often called **hyper-parameters**. \n",
    "\n",
    "However, when we mentioned above that ML applications include parameters that are learnt, we did not mean the hyper-parameters that are decided (semi-)automatically. What we meant with **tunable parameters** were the model's parameters. Every model requires different parameters, e.g. a simple linear regression of 1D data has the following two parameters: the slope and the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # starting from some toy data to get familiar with the concepts:\n",
    "X = np.array([[0],\n",
    "              [1],\n",
    "              [2]]) # A 2D array with 3 samples of 1 feature each\n",
    "y = np.array([[0, 1, 2 ]]).T # What we want to predict as a function of X\n",
    "# # Hint: This is the identity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFkCAYAAACuFXjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkwUAYCSTBQBgpP8Pi8W+s2OqOkEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f59f3204c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Let's plot to verify that we've defined the identity function.\n",
    "_ = plt.plot(X[:, 0], y, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Let's fit the Linear regression model we've defined above.\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # It was that simple. We call the method fit, provide \n",
    "# # the training samples and the model \"learns\" the parameters.\n",
    "# # Let's now print the coefficient learnt for this case:\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now, it's time to move to a more useful example. We will be given some samples X (1D) and try to estimate the linear line that created them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # The seed below is significant for reproducible results.\n",
    "np.random.seed(0)\n",
    "\n",
    "X = np.random.random(size=(20, 1))\n",
    "y = 3 * X[:, 0] + 2 + np.random.normal(size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficient: [ 3.93491126], and intercept: 1.462290789039339\n"
     ]
    }
   ],
   "source": [
    "# # Fit linear regression to it.\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X, y)\n",
    "m1 = 'Model coefficient: {}, and intercept: {}'\n",
    "print(m1.format(model.coef_, model.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Let's now generate some new samples (UNSEEN in the training)\n",
    "# # and use those to predict the y values.\n",
    "X_test = np.linspace(0, 1, 100)[:, np.newaxis]\n",
    "y_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f59f099c588>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAFkCAYAAADBklkAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4MjsT6ARAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f59f099c940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot with blue dots the 'training' points, while with a red line the\n",
    "# estimated line.\n",
    "plt.plot(X, y, 'bo')\n",
    "plt.plot(X_test, y_test, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if you increase the number of training points from 100 to 10K?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A recap on Scikit-learn's estimator interface\n",
    "\n",
    "As you have observed, scikit-learn provides a uniform interface across all methods.In the case of regression, the main functions you will need are:\n",
    "\n",
    "+ `model.fit()` : fit training data. For supervised learning applications,\n",
    "this accepts two arguments: the data `X` and the labels `y` (e.g. `model.fit(X, y)`).\n",
    "For unsupervised learning applications, this accepts only a single argument,\n",
    "the data `X` (e.g. `model.fit(X)`).\n",
    "+ `model.predict()` : given a trained model, predict the label of a new set of data.\n",
    "This method accepts one argument, the new data `X_new` (e.g. `model.predict(X_new)`),\n",
    "and returns the learned label for each object in the array.\n",
    "+ `model.score()` : for classification or regression problems, most (all?) estimators implement\n",
    "a score method.  Scores are between 0 and 1, with a larger score indicating a better fit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now seen how to fit a standard linear regression model with scikit-learn. For statistical analysis, such as hypothesis testing, we would often use another library called [statsmodels](http://www.statsmodels.org/stable/index.html).\n",
    "\n",
    "Now, let's work through a machine-learning application with the Titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning task: Predict survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will employ the Titanic data to predict the chance of survival of the passengers. In other words, the goal of the this part is to predict whether a passenger survived based on other known attributes. This is a very brief introduction and we will not go through all details of the models. When you see a model or a command you're not familiar with, it's a good idea to try to search online for what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survived_column = data['Survived']\n",
    "survived_column.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, the value is 1 if the person survived, 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>424</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>68</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>290</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>136</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PassengerId  Pclass  Name  Sex  Age  SibSp  Parch  Ticket  Fare  \\\n",
       "Survived                                                                    \n",
       "0                 549     549   549  549  424    549    549     549   549   \n",
       "1                 342     342   342  342  290    342    342     342   342   \n",
       "\n",
       "          Cabin  Embarked  \n",
       "Survived                   \n",
       "0            68       549  \n",
       "1           136       340  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use the groupby as we used it above to get the survivors per category:\n",
    "data.groupby('Survived').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38383838383838381"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(survived_column == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, ~38% of the people survived. Let's convert the values of survived into a numpy arrays (input to scikit-learn).\n",
    "\n",
    "`sklearn` estimators all work with homegeneous numerical feature descriptors passed as a numpy array. Therefore passing the raw data frame will not work out of the box.\n",
    "\n",
    "Let us start simple and build a first model that only uses readily available numerical features as input, namely `data.Fare`, `data.Pclass` and `data.Age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2500</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9250</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0500</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.4583</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.0750</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.1333</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30.0708</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fare  Pclass   Age\n",
       "0   7.2500       3  22.0\n",
       "1  71.2833       1  38.0\n",
       "2   7.9250       3  26.0\n",
       "3  53.1000       1  35.0\n",
       "4   8.0500       3  35.0\n",
       "5   8.4583       3   NaN\n",
       "6  51.8625       1  54.0\n",
       "7  21.0750       3   2.0\n",
       "8  11.1333       3  27.0\n",
       "9  30.0708       2  14.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = survived_column.values\n",
    "numerical_features = data[['Fare', 'Pclass', 'Age']]\n",
    "numerical_features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slight issue is that passenger 6 has an age 'NaN', which will not be recognised from sklearn. In general, the first step of any machine learning application is to pre-process the data. \n",
    "\n",
    "Typically, the data are (un)normalised, in a different format than your library requires them, etc. So, you will need to take care that they include the right values at first, otherwise you might end up spending hours trying to understand why the trained models return non-sensical results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fare      15.7417\n",
       "Pclass     2.0000\n",
       "Age       28.0000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_features = numerical_features.dropna().median()\n",
    "median_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this value to replace the missing ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fare      891\n",
       "Pclass    891\n",
       "Age       891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_features = numerical_features.fillna(median_features)\n",
    "imputed_features.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data frame is clean, we can convert it into an homogeneous numpy array of floating point values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_array = imputed_features.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 891 samples: let us keep 700 for training our model and the rest to test the quality of said model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = features_array[:700, :]\n",
    "X_test = features_array[700:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 3)\n",
      "(191, 3)\n"
     ]
    }
   ],
   "source": [
    "# It's always a good idea to verify that your data have the expected shape\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = target[:700]\n",
    "y_test = target[700:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally apply a regression model! We'll use [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression), common for modelling binary data such as survivals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(C=1.)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_predicted = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72774869109947649"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "72 percent accuracy, not **too** bad..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation and interpretation\n",
    "\n",
    "#### Interpreting linear model weights\n",
    "\n",
    "The `coef_` attribute of a fitted linear model such as `LogisticRegression` holds the weights of each features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Fare', 'Pclass', 'Age'], dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = numerical_features.columns\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00340844, -0.80203374, -0.03071402]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAFxCAYAAAAf0vCNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK1QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f59f51d7668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.arange(len(feature_names))\n",
    "plt.bar(x, logreg.coef_.ravel())\n",
    "_ = plt.xticks(x + 0.5, feature_names, rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, survival is slightly positively linked with Fare (the higher the fare, the higher the likelyhood the model will predict survival) while passenger from first class and lower ages are predicted to survive more often than older people from the 3rd class.\n",
    "\n",
    "First-class cabins were closer to the lifeboats and children and women reportedly had the priority. Our model seems to capture that historical information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's your first machine-learning algorithm. Even though you can build much more powerful models, standard linear (or logistic) regression is often remarkably effective for providing an understanding of the complexity of your data. That is, if this error is already quite small with the linear regression model, then you might as well use that.\n",
    "\n",
    "For a much more detailed introduction to machine learning in Python, see\n",
    "- The Python Data Science Handbook, Chapter 5, https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.00-Machine-Learning.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
