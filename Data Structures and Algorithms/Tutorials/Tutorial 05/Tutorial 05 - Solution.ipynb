{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5: Python toolkit: Introduction to Pandas\n",
    "\n",
    "_BS1819 Data Structures and Algorithms, September 2018_\n",
    "\n",
    "_Imperial College Business School_\n",
    "\n",
    "\n",
    "---\n",
    "In the previous tutorial, we worked with the `numpy` library, which is the standard library for numeric manipulations in Python.\n",
    "\n",
    "In this tutorial, we will move to `pandas`, a library that builds on top of numpy with higher level structures to allow convenient and versatile data analysis. Today we will cover the use of pandas for loading data, representing it with common structures (pandas series and dataframes), and manipulating/accessing data within these structures. In the next tutorial, we will continue to work on aggregating and merging data in pandas.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "### Question 0: Recap\n",
    "\n",
    "**A.** Create a Python list containing 100 consecutive multiples of 2, starting from 4, ie 4,6,8, and so on. What is the last element of the list?\n",
    "\n",
    "**B.** What is the sum of the list values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solve the recap exercise here and assign the correct values in \n",
    "# the next cell.\n",
    "L = []\n",
    "\n",
    "for ind in range(100):\n",
    "    L.append(4 + 2*ind)\n",
    "\n",
    "print(L)\n",
    "print(sum(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the command \n",
    "```\n",
    "python ok -q recap -u\n",
    "```\n",
    "on the command line to test your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting your work\n",
    "\n",
    "There are eight questions in total, some on the command line, some in the Notebook. You will get full credit for making a good attempt at most of the questions.\n",
    "\n",
    "After you're done with the exercises below, you'll submit the assignment to OK directly from this Notebook. The submission instructions are in the end of the tutorial.\n",
    "\n",
    "First, let's connect the Notebook to OK. To do so, run the code cell below. It may prompt you to log in. If it does, follow the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "# The result will give you directions on how to log in to the OK submission system.\n",
    "# Once you're logged in, OK should remember it for the duration of the session.\n",
    "import zipimport\n",
    "import os\n",
    "nb_path = os.path.join('client', 'api', 'notebook')\n",
    "ok_bundle =  zipimport.zipimporter('./ok').load_module('client')\n",
    "ok_nb = zipimport.zipimporter('./ok').load_module(nb_path)\n",
    "ok = ok_nb.Notebook('tut05.ok')\n",
    "_ = ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell provides an alternative way to log in to OK if the above way fails on your laptop for some reason. If the login worked, you can skip to the recap exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If your login works with the above cell, no need to run this\n",
    "# If the above cell does not work, this is a backup way of loading up OK\n",
    "# Don't change this cell; just run it. \n",
    "!pip install -U okpy\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('tut05.ok')\n",
    "_ = ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the OK problem still persists, try the following steps: \n",
    "1. Go to the command line and navigate to the folder where you have this Notebook.\n",
    "2. Run the command `python ok` and log in the standard way\n",
    "3. Try running the first cell above again.\n",
    "The questions ask you to use Python. You can do so below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Pandas builds on top of numpy and matplotlib to provide data analysis and statistical functionalities in Python. \n",
    "\n",
    "We will first introduce some core aspects of pandas using toy data, and then analyse a real data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # We import the numpy library to generate some random data.\n",
    "# # Also the pandas library is imported.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# # We fix the seed so that the results are reproducible.\n",
    "# # Please do not change the seed below.\n",
    "np.random.seed(seed=9)\n",
    "# # Let's generate some toy data (sampled from a Gaussian distribution)\n",
    "values = np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of the work we do with pandas revolves around the use of _DataFrames_ to organize data. A DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet. If you've used R, chances are you've already used dataframes. The functionalities are very similar. The data structures in pandas build on and wrap around most popular data-types of python, e.g. lists, numpy arrays, so it's easy to move from one to another and call functions that work on a specific structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Let's use the numpy vector that we created above to create a DataFrame.\n",
    "dataframe = pd.DataFrame(data=values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pandas also includes most of the core methods/properties of a numpy array.\n",
    "# # For instance, you can call get the shape the same way as in a numpy array.\n",
    "print(dataframe.shape)\n",
    "\n",
    "# # Few additional methods that are exactly the same (in the way you call them)\n",
    "# # as in the numpy arrays are the max, min, median, mean, sum, std (standard \n",
    "# # deviation) methods.\n",
    "print(dataframe.max())\n",
    "\n",
    "# # The max value should be 2.45. But notice the result is not a simple value \n",
    "# # but a pandas data \"series\"\n",
    "print('Result type:', type(dataframe.max()))\n",
    "\n",
    "# # To get only the max value without the additional information, you \n",
    "# # could do: \n",
    "print(dataframe.max()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Dataframe summary\n",
    "\n",
    "**A.** What is the min value of the dataframe?\n",
    "\n",
    "**B.** What is the mean value of the dataframe?\n",
    "\n",
    "**C.** Now create a new DataFrame named `dataframe_10k` that includes a vector of 10000 elements sampled from a Gaussian as above. What is the mean value now? ** Hint ** Remember to copy the same seed as above to ensure that you create the same array as in the test. The random.seed and the creation of the matrix should be in the same cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the next line so that min_elem_df contains the min\n",
    "# element of dataframe. \n",
    "# The expected result is ONLY the min value.\n",
    "min_elem_df = dataframe.min()[0]\n",
    "\n",
    "\n",
    "# Change the next line so that mean_elem_df contains the mean\n",
    "# element of dataframe. \n",
    "# The expected result is ONLY the mean value.\n",
    "mean_elem_df = dataframe.mean()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Please do not modify the line below (allows us to replicate the results).\n",
    "np.random.seed(seed=9)\n",
    "\n",
    "# The lines below concern part C of Question 1. \n",
    "# Modify the line below so that it creates the dataframe of 10k elements\n",
    "# as mentioned in the description (part C above).\n",
    "dataframe_10k = pd.DataFrame(np.random.randn(10000, 1))\n",
    "\n",
    "# Change the next line so that mean_10k contains the mean\n",
    "# element of dataframe_10k. \n",
    "mean_10k = dataframe_10k.mean()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test cell; please do not change!\n",
    "_ = ok.grade('q1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen how a DataFrame is initiated and some methods that it includes, you might wonder the benefits over using a numpy array. \n",
    "\n",
    "Here are some important differences between the two:\n",
    "\n",
    "* A numpy array demands homogeneous data, while in a dataframe, different data types (float, string, datetime) are allowed in the same structure.\n",
    "* Numpy is an amazing low-level tool for data manipulation, required by most other libraries (including pandas). However, pandas offers a  plethora of high-level functionality, e.g. grouping data by conditions (using the groupby method) and combining datasets with merge and join methods. We will see these methods later.\n",
    "* The data (columns/rows) can have labels in pandas. In numpy the programmer needs to keep in mind the semantics of each column/row, while in dataframe they are explicitly coded in the structure.\n",
    "\n",
    "Let's study an example that utilises some of these ideas. We'll create a small dataset of a few countries with the countries names, population, GDP, a d country codes. This sounds like a problem where we might use dictionary. Indeed the dictionary is convenient for housing this kind of data. However, data/number processing with a dictionary can be cumbersome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1 = {}\n",
    "d1['countries'] = ['UK', 'France', 'Spain', 'Netherlands']\n",
    "d1['codes'] = ['uk', 'fr', 'es', 'nl']\n",
    "# # the population is measured in millions\n",
    "d1['population'] = [65.6, 66.9, 46.6, 17.0]\n",
    "# # the gdp is measured in billions\n",
    "d1['gdp'] = [2619, 2465, 1232, 770]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's create a dataframe now with that data.\n",
    "# # DataFrame includes a convenience constructor that\n",
    "# # just accepts the dictionary data and creates\n",
    "# # the same structure as in the previous example.\n",
    "countries_data = pd.DataFrame(d1)\n",
    "\n",
    "print(countries_data['gdp'])\n",
    "countries_data # Notebook gives a nice HTML table of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Additionally, we can call the aggregation methods as above, but now we get\n",
    "# # a result per column (which makes sense, we do not want to average\n",
    "# # gdps together with populations).\n",
    "countries_data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: More summaries\n",
    "\n",
    "**A.** What is the sum of the populations in the `countries_data`?\n",
    "\n",
    "**B.** What is the standard deviation of the gdp's in the `countries_data`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the next line so that sum_pop_countries_data computes the sum of\n",
    "# the populations from countries_data.\n",
    "# (by default the answer is expected to have one decimal)\n",
    "sum_pop_countries_data = round(countries_data.sum()['population'],1)\n",
    "\n",
    "# Change the next line so that std_gdp_countries_data computes the std of\n",
    "# the gdp from countries_data.\n",
    "# (by default the answer is expected to have one decimal)\n",
    "std_gdp_countries_data = round(countries_data.std()['gdp'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test cell; please do not change!\n",
    "_ = ok.grade('q2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File loading, data processing with Pandas\n",
    "\n",
    "Now that you've become familiar with Dataframe, let's scale up our exploration and download a real dataset. We will use the Titanic dataset from the Kaggle Getting Started challenge at:\n",
    "\n",
    "https://www.kaggle.com/c/titanic-gettingStarted\n",
    "\n",
    "The dataset is included with the tutorial as `titanic.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# make sure matplotlib plots display nicely in the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's load the first csv file. \n",
    "data = pd.read_csv('titanic.csv')\n",
    "\n",
    "# # Printing the shape of the dataset we have just loaded.\n",
    "print(data.shape)\n",
    "\n",
    "# # The first step in data analysis is the exploration step.\n",
    "# # We want to verify that a) our dataset is appropriately loaded,\n",
    "# # b) get a sense of what values it has.\n",
    "# # Let's display the 5 first rows:\n",
    "data.head(5)\n",
    "# # (When we run this in the Notebook, we will get a nice \n",
    "# #  HTML representation of the table.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract some info from what we have just printed:\n",
    "\n",
    "As you've noticed, each row has an id, starting from zero, and the data columns have names that help us categorise the values of the columns. For instance, the fourth column includes the names of the passengers and the sixth their ages. \n",
    "In the Cabin column, notice that there are some 'NaN' values. 'NaN' typically denotes a missing value in pandas.\n",
    "\n",
    "Pandas includes a lot of built-in tools and methods that produce useful insights for our data. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pandas also allow us to plot values directly. \n",
    "# # Let's plot a histogram of the age of the passengers\n",
    "# # pandas wraps around the relevant matplotlib function to directly do plotting. \n",
    "# # We could also import matplotlib as before\n",
    "data.hist(column='Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For accessing a specific value of a column you can you use the at[] property or the get() method, like this:\n",
    "\n",
    "```python\n",
    ">>> data.at[0, 'Age']\n",
    "22\n",
    ">>> data.get('Age')\n",
    "# the entire column\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Accessing a dataframe\n",
    "\n",
    "**A.** What is the age of the 10th passenger (i.e. PassengerId is 10)?\n",
    "\n",
    "**B.** What is the cabin value for the 194th passenger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the next line so that age_passenger_10 computes the age of\n",
    "# the 10th passenger.\n",
    "age_passenger_10 = data.at[9, 'Age']\n",
    "\n",
    "# Change the next line so that cabin_194_passenger computes the \n",
    "# cabin number of the 194th passenger.\n",
    "cabin_194_passenger = data.at[193, 'Cabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test cell; please do not change!\n",
    "_ = ok.grade('q3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: More accessing\n",
    "\n",
    "Fill in the line of code below and then test it using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the next line so that it computes ticket number/id of\n",
    "# the 100th passenger\n",
    "ticket_i_th_passenger = data.at[99,'Ticket']\n",
    "\n",
    "# We've put this line in this cell so that it will print\n",
    "# the value you've given to ticket_i_th_passenger when you\n",
    "# run it.  You don't need to change this.\n",
    "ticket_i_th_passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test cell; please do not change!\n",
    "_ = ok.grade('q4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data modification with pandas\n",
    "\n",
    "In addition to parsing data, pandas can be used to modify data tables. We will go through a few common methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's delete the first and the third \n",
    "# # passengers (remember the indexing in \n",
    "# # python starts from 0).\n",
    "data.drop([0, 2], axis=0).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apart from that, you can also delete whole columns or rows.\n",
    "# # For instance, for your problem, the Cabin column might be \n",
    "# # irrelevant, let's delete it.\n",
    "data.drop(['Cabin'], axis=1).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now print the first five elements to check how the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a minute to consider what pandas have printed for you...\n",
    "\n",
    "You might have observed, that the 'Cabin' column that we deleted above (the result showed it was deleted above) is still there. You will also notice, that even the elements that we deleted (passengers 1 and 3) are also re-added. Or were they never deleted in the first place? \n",
    "\n",
    "By default in pandas `drop` is not \"inplace\": in other words, the function returns you a *copy* while the original is untouched. However, since the copy is of the same type, you can assign it to a new variable, which will now contain only the reduced elements/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's check that the data type is the same.\n",
    "print(type(data))\n",
    "# # What about the return type from a drop operation?\n",
    "print(type(data.drop(['Cabin'], axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Assign to the variable `reduced_data` the pandas matrix that does not include the columns of Cabin, Embarked and SibSp. Then execute the cell below for testing with the ok system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the next line so that it computes the reduced data matrix.\n",
    "reduced_data = data.drop(['Cabin','Embarked','SibSp'], axis=1)\n",
    "\n",
    "# We've put this line in this cell so that it will print\n",
    "# the value you've given to reduced_data when you\n",
    "# run it.  You don't need to change this.\n",
    "reduced_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell; please do not change!\n",
    "_ = ok.grade('q5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from deleting, you can also replace values by new ones. Remember that the main purpose of pandas is statistical computation, hence we often translate values to numbers that we know how to process. \n",
    "\n",
    "For instance, strings, such as 'male' or 'female' are not really useful for statistical analysis. We usually prefere to replace them with numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace('male', 1).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with drop, the replace function returns a copy, so keep in mind that if you want to save them, you have to assign to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # An alternative way to replace the data is the following:\n",
    "data['Sex'] = data['Sex'].map({'female': 1, 'male': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now assume that from an external source, you figure out the Nationality of the passengers and want to insert that information. Pandas allow you to insert new rows, and in contrast with the aforementioned methods, this is an in-place operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Right after the Sex, we want to include a new field named 'Nationality'. \n",
    "# # Since most of the passengers are Irish, we will by default assign \n",
    "# # the label 'Irish' to them and refine for those that are not.\n",
    "data.insert(5, 'Nationality', 'Irish')\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have replaced the values of a complete column, however what if we want to perform some modifications in specific values per row (e.g. if a condition is true)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Let's assume for a moment that the nationality of \n",
    "# # those with Age NaN is Other European (hence why there \n",
    "# # are no records of their age).\n",
    "# # We want to replace the default nationality with\n",
    "# # their known nationality.\n",
    "import numpy as np\n",
    "for index, row in data.iterrows():\n",
    "    if np.isnan(data.loc[index, \"Age\"]):\n",
    "        data.loc[index, \"Nationality\"] = \"European\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # What we've done above is to replace some of the nationalities with 'European'. \n",
    "# # One property of pandas that we've utilised for that is the '.loc'.\n",
    "# # Let's explore that a bit more: \n",
    "print(data.loc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be easily verified from the print above, this provides the whole row of the 4th passenger (as Python follows zero-based indexing). In other words, data.loc is a way to index a row or even a specific 'cell' inside the row as we did above with `data.loc[index, \"Nationality\"]'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # As typically done in higher level libraries in python, '.loc' offers a great deal of functionality. \n",
    "# # You can find furthr information by executing data.loc??\n",
    "help(data.loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter dataframes directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "european_bool = data['Nationality'] == 'European' # creates Booleans for each entry\n",
    "print(european_bool.head(10))\n",
    "# We could then pick only these records with \n",
    "europeans = data[european_bool]\n",
    "# If we want to count different values, we can do \n",
    "data['Nationality'].value_counts()\n",
    "# Counting how many non null values exist would be data['Nationality'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review questions\n",
    "\n",
    "In this tutorial, we've been introduced to the pandas library for data analysis. Based on your newly acquired knowledge, how would you answer the following?\n",
    "\n",
    "* Why is pandas library useful when there is numpy? \n",
    "* Can you manipulate the pandas tables? Or are they read-only?\n",
    "\n",
    "Pandas is the workhorse of the Python analytics community. In the next tutorial, we will build on today's material with pandas's powerful data aggregation methods, and do a brief introduction to machine learning with the `scikit-learn` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________\n",
    "\n",
    "**Important**. Before you leave lab, run this final cell to submit your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional exercises\n",
    "\n",
    "### Question 6\n",
    "\n",
    "**A.** Can you replace the nationalit column with numbers? For instance, try to assign values such that Irish = 0, Other European = 1. \n",
    "\n",
    "**B.** How many people of European nationality are there? (Following the assumption above for the NaN in the age)\n",
    "\n",
    "**C.** For how many passengers do we have with Cabin information?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the next line so that it computes the number of\n",
    "# people with European nationality.\n",
    "\n",
    "data['Nationality']=data['Nationality'].map({'Irish':0,'European':1})\n",
    "\n",
    "n_european = data['Nationality'].sum()\n",
    "\n",
    "# Change the next line so that it computes the number of\n",
    "# people for which we have cabin information.\n",
    "n_passengers_cabin = data['Cabin'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test cell; please do not change!\n",
    "_ = ok.grade('q6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Assign to the variable `only_pclass2` the pandas matrix that includes only the passengers with Pclass = 2. Then execute the cell below for testing with the ok system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the next line so that it computes a new dataframe\n",
    "# that includes only the people with Pclass = 2.\n",
    "# One way to use conditions in pandas is directly with data[CONDITION]\n",
    "only_pclass2 = data[data['Pclass']==2]\n",
    "\n",
    "# We've put this line in this cell so that it will print\n",
    "# the value you've given to only_pclass2 when you\n",
    "# run it.  You don't need to change this.\n",
    "only_pclass2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test cell; please do not change!\n",
    "_ = ok.grade('q7')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
